{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from typing import Tuple\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(0,1,size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw = np.arange(0,1000,1)\n",
    "y_raw = 5*x_raw + 20 + np.random.normal(0,1000,size = len(x_raw))\n",
    "random_indexes_to_change = np.random.randint(0,len(x_raw), int(len(x_raw)*0.1))\n",
    "y_raw[random_indexes_to_change] = np.random.uniform(-10,10,size = len(random_indexes_to_change)) * y_raw[random_indexes_to_change] # Random outliers\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "x = x_scaler.fit_transform(x_raw.reshape(-1,1))\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y = y_scaler.fit_transform(y_raw.reshape(-1,1)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(x.reshape(-1,1),y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huberreg = HuberRegressor()\n",
    "huberreg.fit(x.reshape(-1,1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            threshold: float = 0.685,\n",
    "            weight_max_error: float = 1,\n",
    "            weight_percentage_above_threshold:float = 1,\n",
    "            weight_wrong_sign: float = 1,\n",
    "            sigmoid_steepness: float = 1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.steepness = sigmoid_steepness\n",
    "        self.threshold = threshold\n",
    "        # Normalize weights and assign them\n",
    "        sum_weights = (\n",
    "            weight_max_error\n",
    "            + weight_percentage_above_threshold\n",
    "            + weight_wrong_sign\n",
    "        )\n",
    "        self.weight_max_error = (\n",
    "            weight_max_error / sum_weights\n",
    "        )\n",
    "        self.weight_percentage_above_threshold = (\n",
    "            weight_percentage_above_threshold / sum_weights\n",
    "        )\n",
    "        self.weight_wrong_sign = (\n",
    "            weight_wrong_sign / sum_weights\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            inputs: torch.Tensor, \n",
    "            targets: torch.Tensor,\n",
    "        ) -> torch.Tensor:\n",
    "\n",
    "        residuals = targets - inputs\n",
    "        # Maximum abs error\n",
    "        max_error = residuals.abs().max()\n",
    "\n",
    "        # Percentage of time above threshold value\n",
    "        percentage_of_time_above_x = (\n",
    "            1/(1+torch.e**(-self.steepness*(residuals.abs()-self.threshold)))\n",
    "        ).mean()\n",
    "\n",
    "        # Percentage of time wrong sign\n",
    "        loss_percentage_of_time_wrong_sign = (\n",
    "            1/(1+torch.e**(-self.steepness*(inputs*targets)))\n",
    "        ).mean()\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = (\n",
    "            self.weight_max_error * max_error\n",
    "            + self.weight_percentage_above_threshold * percentage_of_time_above_x\n",
    "            + self.weight_wrong_sign * loss_percentage_of_time_wrong_sign\n",
    "        )\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_features: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=n_features,\n",
    "            out_features=1,\n",
    "        )  # Just 1 fully connected layer without activation, i.e. a linear regression.\n",
    "\n",
    "    def forward(\n",
    "        self,  \n",
    "        X: torch.Tensor,  \n",
    "    ) -> torch.Tensor:\n",
    "        y = self.fc1(X)\n",
    "        return y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            X: torch.Tensor,\n",
    "            y: torch.Tensor,\n",
    "        ) -> None:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(\n",
    "            self\n",
    "    ) -> int:\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(\n",
    "            self,\n",
    "            idx: int,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        X_item = self.X[idx,:]\n",
    "        y_item = self.y[idx]\n",
    "        return X_item, y_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMSELoss(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            inputs: torch.Tensor, \n",
    "            targets: torch.Tensor,\n",
    "        ) -> torch.Tensor:\n",
    "\n",
    "        residuals = targets - inputs\n",
    "        mse = (residuals**2).mean()\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMAELoss(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            inputs: torch.Tensor, \n",
    "            targets: torch.Tensor,\n",
    "        ) -> torch.Tensor:\n",
    "\n",
    "        residuals = targets - inputs\n",
    "        mae = residuals.abs().mean()\n",
    "        return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "lr = 1e-4\n",
    "batch_size = 100\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    CustomDataset(\n",
    "        torch.Tensor(x).float(),\n",
    "        torch.Tensor(y).float(),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "model_rmse = Model(\n",
    "    n_features=1,\n",
    ")\n",
    "optimizer = torch.optim.Adam(\n",
    "    model_rmse.parameters(),\n",
    "    lr = lr,\n",
    ")\n",
    "# criterion = CustomLoss(\n",
    "#     weight_max_error=1,\n",
    "#     weight_percentage_above_threshold=1,\n",
    "#     weight_wrong_sign=1,\n",
    "# )\n",
    "# criterion = nn.KLDivLoss()\n",
    "criterion = CustomMSELoss()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i,(X_batch, y_batch) in enumerate(dataloader):\n",
    "        prediction = model_rmse(X_batch).flatten()\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(prediction, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        average_loss = epoch_loss/(i+1)\n",
    "    print(f\"Average epoch loss: {average_loss}\")\n",
    "    print(f\"Epoch {epoch} done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmse.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmse.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line1 = np.ones_like(y)*3\n",
    "# line2 = 0.25*x\n",
    "# line3 = 4*x\n",
    "\n",
    "# ax.plot(x,line1, color = \"red\")\n",
    "# ax.scatter(x,line1, color = \"red\")\n",
    "\n",
    "# ax.plot(x, line2, color = \"black\")\n",
    "# ax.scatter(x, line2, color = \"black\")\n",
    "\n",
    "# ax.plot(x, line3, color = \"green\")\n",
    "# ax.scatter(x, line3, color = \"green\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": x.flatten(),\n",
    "        \"y\": y,\n",
    "        \"torch_custom_loss\":model_rmse(torch.Tensor(x).float()).detach().numpy(),\n",
    "        \"huber\": huberreg.predict(x.reshape(-1,1)),\n",
    "        \"sklearn_rmse\": linreg.predict(x.reshape(-1,1)),\n",
    "    }\n",
    ")\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df_molten = prediction_df.melt(id_vars=\"x\")\n",
    "prediction_df_molten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    prediction_df_molten,\n",
    "    x = \"x\",\n",
    "    y = \"value\",\n",
    "    color = \"variable\",\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simplify-deployment-2FnGvFJr-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
